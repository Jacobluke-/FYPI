{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifying names.ipynb",
      "provenance": [],
      "mount_file_id": "10-xmp73nkz61KFmLYFp20W7GEHtM0F_A",
      "authorship_tag": "ABX9TyOuoL4Tf8B9zGuxby7rYkgJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacobluke-/FYPI/blob/main/Pytorch_Tutorial/Classifying_names.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWGKxEONL8T4",
        "outputId": "5e54aedc-4fa0-427c-b6f0-c041b0c5fedf"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def findFiles(path): return glob.glob(path)\n",
        "\n",
        "print(findFiles('data/names/*.txt'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['data/names/Irish.txt', 'data/names/Spanish.txt', 'data/names/Scottish.txt', 'data/names/French.txt', 'data/names/Greek.txt', 'data/names/Dutch.txt', 'data/names/Czech.txt', 'data/names/Arabic.txt', 'data/names/Vietnamese.txt', 'data/names/Russian.txt', 'data/names/English.txt', 'data/names/Japanese.txt', 'data/names/Portuguese.txt', 'data/names/Korean.txt', 'data/names/Chinese.txt', 'data/names/Polish.txt', 'data/names/Italian.txt', 'data/names/German.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3EYbMDyNnYr",
        "outputId": "669380be-d047-475f-d7ce-9d885769b2de"
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# Turn a Unicode string to plain ascii\n",
        "def unicodeToAscii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn'\n",
        "      and c in all_letters\n",
        "  )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "def readLines(filename):\n",
        "  lines = open(filename, encoding = 'utf-8').read().strip().split('\\n')\n",
        "  return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "  category = os.path.splitext(os.path.basename(filename))[0]\n",
        "  all_categories.append(category)\n",
        "  lines = readLines(filename)\n",
        "  category_lines[category] = lines\n",
        "  \n",
        "\n",
        "n_categories = len(all_categories)\n",
        "print(category_lines['Italian'][:5])\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slusarski\n",
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba6Zc9Xk1Nms"
      },
      "source": [
        "# 我们获得了一个变量 category_lines，而这是一个字典，所以则是类别（语言），\n",
        "# 对应值是一个列表，其中包含多行数据（姓氏）\n",
        "# 同时，还保存了 all_categories （语言列表） 以及 n_categories（语言数量）"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK3E_5Kl1uSP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RPtFS0x3Dbd"
      },
      "source": [
        "## 将姓氏转换为张量\n",
        "为了表示单个字母，我们使用大小为<1 x n_letters>的“ one-hot vector”。 一个“one hot”向量是当前字母的索引处为 1，其余部分为 0 的向量，例如 \"b\" = <0 1 0 0 0 ...>。\n",
        "\n",
        "我们将每行的所有字母的“one hot”向量连接成 2D 矩阵<line_length x 1 x n_letters>来表示一个单词（姓氏）。\n",
        "\n",
        "额外的 1 维是因为 PyTorch 假设所有内容都是批量的-我们这里批量大小为 1 。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wFb1oa4yEA",
        "outputId": "04b909b4-c68a-4b67-9bb5-34bf92a01a2d"
      },
      "source": [
        "import torch\n",
        "a = torch.zeros(1,26)\n",
        "a[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDiTOfFe3ecf"
      },
      "source": [
        "import torch\n",
        "\n",
        "def letterToIndex(letter):\n",
        "  return all_letters.find(letter)\n",
        "\n",
        "def letterToTensor(letter):\n",
        "  tensor = torch.zeros(1,n_letters)\n",
        "  tensor[0][letterToIndex(letter)] = 1\n",
        "  return tensor\n",
        "\n",
        "def lineToTensor(line):\n",
        "  tensor = torch.zeros(len(line),1,n_letters)\n",
        "  for li, letter in enumerate(line):\n",
        "    tensor[li][0][letterToIndex(letter)]=1\n",
        "  return tensor"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3AYFaFm5GtO",
        "outputId": "f47947de-dfb9-4155-cbe9-05938ffb92fb"
      },
      "source": [
        "print(n_letters)\n",
        "print(all_letters.find(\"r\"))\n",
        "a = letterToTensor(\"r\")\n",
        "print(a)\n",
        "print(lineToTensor('Jacob'))\n",
        "print(lineToTensor('Jacob').size())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "17\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0.]])\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0.]]])\n",
            "torch.Size([5, 1, 57])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew0V__Ez6pmb"
      },
      "source": [
        "# Construct a neural network\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(RNN, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    combined = torch.cat((input, hidden),1)\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    output = self.softmax(output)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EvFQ3IuIjIC"
      },
      "source": [
        "先测试单步运行， 传递一个字母的张量与上一步的隐藏状态（初始化其为0）。 返回的结果是每种语言的概率与下一步的隐藏状态（保留至下一步使用）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvW52tOLHZm0",
        "outputId": "94cee657-8577-4379-a4c3-fc1f9bc9e4af"
      },
      "source": [
        "input = letterToTensor('Jacob')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input, hidden)\n",
        "print(output, \"\\n\", next_hidden)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.8662, -2.9319, -2.8176, -2.9756, -2.8815, -2.9386, -3.0103, -2.9071,\n",
            "         -2.9440, -2.7864, -2.8506, -2.7800, -2.9132, -2.8188, -2.8520, -2.9681,\n",
            "         -2.9079, -2.9135]], grad_fn=<LogSoftmaxBackward>) \n",
            " tensor([[ 0.0238, -0.0183, -0.0456,  0.0060, -0.0294, -0.0789,  0.0797, -0.0074,\n",
            "         -0.0161, -0.0321,  0.1135,  0.0613, -0.0208,  0.0706, -0.0929, -0.0139,\n",
            "         -0.0921, -0.0189, -0.0227,  0.0176,  0.0132, -0.0062, -0.0909,  0.0542,\n",
            "         -0.0481, -0.0651, -0.0521, -0.0416,  0.0437, -0.0409, -0.0659,  0.0965,\n",
            "         -0.1046, -0.0313,  0.0325,  0.0513,  0.0277, -0.0948,  0.0536,  0.0303,\n",
            "         -0.1007, -0.0630,  0.0497, -0.0741,  0.0746, -0.1241, -0.0425,  0.0224,\n",
            "          0.0420, -0.0527,  0.0939,  0.0310, -0.0609,  0.0144, -0.0719,  0.0532,\n",
            "         -0.0349, -0.1100, -0.0270, -0.0312,  0.0965,  0.0909,  0.0038,  0.0447,\n",
            "         -0.0351,  0.0415,  0.0908, -0.0580, -0.1293,  0.0221, -0.0104,  0.0224,\n",
            "          0.0028, -0.0269,  0.0347,  0.0402,  0.0095,  0.0749,  0.0143,  0.0219,\n",
            "         -0.0361,  0.0628,  0.0369, -0.0107,  0.0958,  0.0916, -0.0758,  0.0262,\n",
            "          0.1228, -0.1025,  0.0363,  0.0081,  0.0282, -0.0312,  0.0574,  0.0492,\n",
            "         -0.1376, -0.0883,  0.0092, -0.0205, -0.0113,  0.0964, -0.0441,  0.0103,\n",
            "         -0.0617, -0.0457, -0.0462, -0.1087,  0.0243, -0.0826,  0.0015, -0.0092,\n",
            "         -0.1203, -0.0215, -0.0271, -0.0573, -0.0366,  0.0287,  0.0419,  0.0781,\n",
            "          0.1068,  0.0097,  0.0359, -0.0621, -0.0201, -0.0169,  0.0913,  0.1106]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UMnCSEQJe-k",
        "outputId": "72e212f2-c408-43bd-9610-a191e7853d03"
      },
      "source": [
        "input = lineToTensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)\n",
        "\n",
        "def categoryFromOutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryFromOutput(output))\n",
        "print(output.topk(1))\n",
        "print(category_lines['Arabic'])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.8980, -2.8657, -2.8503, -2.8620, -2.8573, -2.9138, -2.9576, -2.9687,\n",
            "         -2.8908, -2.8126, -2.8690, -2.8361, -2.9298, -2.8677, -2.8776, -2.9520,\n",
            "         -2.9548, -2.8804]], grad_fn=<LogSoftmaxBackward>)\n",
            "('Portuguese', 9)\n",
            "torch.return_types.topk(\n",
            "values=tensor([[-2.8126]], grad_fn=<TopkBackward>),\n",
            "indices=tensor([[9]]))\n",
            "Type license() to see the full license text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azi8AYeVL-dx",
        "outputId": "1a2cdb10-fe59-401b-e194-5f0e420ee45d"
      },
      "source": [
        "import random\n",
        "\n",
        "def randomChoice(l):\n",
        "    return l[random.randint(0, len(l) - 1)]\n",
        "\n",
        "def randomTrainingExample():\n",
        "    category = randomChoice(all_categories)\n",
        "    line = randomChoice(category_lines[category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
        "    line_tensor = lineToTensor(line)\n",
        "    return category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
        "    print('category =', category, '/ line =', line)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category = Dutch / line = Schoonraad\n",
            "category = French / line = Tremble\n",
            "category = Vietnamese / line = Luong\n",
            "category = Dutch / line = Sanna\n",
            "category = English / line = Perrins\n",
            "category = Portuguese / line = Franco\n",
            "category = Chinese / line = Ding\n",
            "category = Italian / line = Pietri\n",
            "category = Chinese / line = Cheung\n",
            "category = Spanish / line = Noguerra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMmNKdZLPA9t"
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "    hidden = rnn.initHidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "\n",
        "    for i in range(line_tensor.size()[0]):\n",
        "        output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "    loss = criterion(output, category_tensor)\n",
        "    loss.backward()\n",
        "\n",
        "    # Add parameters' gradients to their values, multiplied by learning rate\n",
        "    for p in rnn.parameters():\n",
        "        p.data.add_(-learning_rate, p.grad.data)\n",
        "\n",
        "    return output, loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}